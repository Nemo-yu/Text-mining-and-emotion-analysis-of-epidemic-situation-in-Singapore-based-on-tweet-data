{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Analysis of data come from Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import os\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary, Vectorizer, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "      \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx         \n",
    "                                                  \n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token             # for paddding, e.g., [2, 6, 7, 16, 13, ..., 3, 0, 0, 0, 0, 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)            # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)              # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)  # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)      # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"   \n",
    "    def __init__(self, tweet_vocab, sentiment_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            char_vocab (Vocabulary): maps characters to integers\n",
    "            nationality_vocab (Vocabulary): maps nationalities to integers\n",
    "        \"\"\"\n",
    "        self.tweet_vocab = tweet_vocab\n",
    "        self.sentiment_vocab = sentiment_vocab\n",
    "    def vectorize(self, tweet, vector_length=-1):\n",
    "        \n",
    "        indices = [self.tweet_vocab.begin_seq_index]\n",
    "        indices.extend(self.tweet_vocab.lookup_token(token) \n",
    "                       for token in tweet.split(\" \"))\n",
    "        indices.append(self.tweet_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.tweet_vocab.mask_index\n",
    "\n",
    "        return out_vector, len(indices)\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, tweet_df):\n",
    "    \n",
    "        sentiment_vocab = Vocabulary()        \n",
    "        for sentiment in sorted(set(tweet_df.sentiment)):\n",
    "            sentiment_vocab.add_token(sentiment)\n",
    "\n",
    "        word_counts = Counter()\n",
    "        for tweet in tweet_df.tweet:\n",
    "            for token in tweet.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counts[token] += 1\n",
    "        \n",
    "        tweet_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "                tweet_vocab.add_token(word)\n",
    "        \n",
    "        return cls(tweet_vocab, sentiment_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, tweet_df, vectorizer):\n",
    "      \n",
    "        self.tweet_df = tweet_df \n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self._max_seq_length = max(map(len, self.tweet_df.tweet)) + 2   # add 2 for begin_seq_token and end_seq_token\n",
    "\n",
    "        self.train_df = self.tweet_df[self.tweet_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.tweet_df[self.tweet_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.tweet_df[self.tweet_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights\n",
    "        class_counts = self.train_df.sentiment.value_counts().to_dict()   # {'English': 2972, 'Russian': 2373, ....}\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.sentiment_vocab.lookup_token(item[0]) # e.g, index of English is 4\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)          # sort by the index number of nationality_vocab\n",
    "                                   # {('Arabic', 1603), ('Chinese', 220), ('Czech', 414), ('Dutch', 236),('English', 2972), ...}\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32) # [1/1603, 1/220, 1/414, 1/236, 1/2972, ...]\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, tweet_csv):\n",
    "     \n",
    "        \n",
    "        tweet_df = pd.read_csv(tweet_csv,encoding=\"latin2\")\n",
    "        tweet_df.columns = ['tweet','sentiment','split']\n",
    "        \n",
    "        EngWords=set(nltk.corpus.words.words())\n",
    "        #StopWords= set(nltk.corpus.stopwords.words(\"english\"))\n",
    "        wnl=nltk.WordNetLemmatizer()\n",
    "        \n",
    "        for i in range(len(tweet_df)):\n",
    "            tweet_str=tweet_df.loc[i,\"tweet\"]\n",
    "            words=nltk.word_tokenize(tweet_str)\n",
    "            words=[wnl.lemmatize(word.lower()) for word in words]\n",
    "            tweet_str=\" \".join(words)\n",
    "            tweet_df.loc[i,'tweet']=tweet_str\n",
    "        \n",
    "        \n",
    "        train_tweet_df = tweet_df[tweet_df.split=='train']\n",
    "        return cls(tweet_df, TweetVectorizer.from_dataframe(train_tweet_df))\n",
    "        \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "       \n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        tweet_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.tweet, self._max_seq_length)\n",
    "        \n",
    "        sentiment_index = \\\n",
    "            self._vectorizer.sentiment_vocab.lookup_token(row.sentiment)\n",
    "\n",
    "        return {'x_data': tweet_vector,       # 'x_data': [2, 5, 6, 5, 7, 8, 7, 9, 3, 0, 0, 0, ..., 0]\n",
    "                'y_target': sentiment_index,  # 'y_target': 4              \n",
    "                'x_length': vec_length}         # 'x_length': 9\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size   \n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=False,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1   # deduct 1 since the index starts from 0\n",
    "                                                              # e.g., [9, 6, 11, 9, 7, ...., 12]\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths): # out gets the last hidden vector of each input: (batch, hidden_size)\n",
    "        out.append(y_out[batch_index, column_index]) # e.g., y_out[0, 9], y_out[1, 6]\n",
    "\n",
    "    return torch.stack(out)  # (batch, hidden_size*num_directions); E.g., (64, 64*num_direction)\n",
    "\n",
    "def column_summation(y_out, x_lengths, mode=\"mean\"):\n",
    "    '''Get a max or mean vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the max or mean vector of all the vectors by \n",
    "    the position indicated by the corresponding value in `x_lengths` at the row index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "        mode: \"mean\" for mean vector; \"max\" for max vector\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        if mode == \"mean\":\n",
    "            # replace \"pass\" with your code to get the mean vector of current batch item from y_out[], and append it to out list.\n",
    "            mean_out=torch.mean(y_out[batch_index],dim=0)\n",
    "            out.append(mean_out)\n",
    "        else:\n",
    "            # replace \"pass\" with your code to get the max vector of current batch item from y_out[], , and append it to out list.\n",
    "            max_out=torch.max(y_out[batch_index],dim=0)[0]\n",
    "            out.append(max_out)\n",
    "    return torch.stack(out)\n",
    "\n",
    "class TweetClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, bidirectional=False, batch_first=True, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): The size of the character embeddings\n",
    "            num_embeddings (int): The number of characters to embed\n",
    "            num_classes (int): The size of the prediction vector \n",
    "                Note: the number of nationalities\n",
    "            bidirectional (bool): Informs whether bidrectional RNN is used\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool): Informs whether the input tensors will \n",
    "                have batch or the sequence on the 0th dimension\n",
    "            padding_idx (int): The index for the tensor padding; \n",
    "                see torch.nn.Embedding\n",
    "        \"\"\"\n",
    "        super(TweetClassifier, self).__init__()\n",
    "\n",
    "        if bidirectional == False:\n",
    "             self.num_directions = 1\n",
    "        else:\n",
    "             self.num_directions = 2\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,    # E.g., (80, 100)\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)\n",
    "\n",
    "        #self.rnn = nn.RNN(input_size=embedding_size,              # E.g., 100\n",
    "        #self.rnn = nn.GRU(input_size=embedding_size,\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,         # E.g., 64\n",
    "                             batch_first=batch_first, \n",
    "                             num_layers = 1,\n",
    "                             dropout = 0.0, \n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,  # 64*1 for unidirectinal; 64*2 for bidirectional\n",
    "                         out_features=rnn_hidden_size*self.num_directions)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "                          out_features=num_classes)                            # 18 classes\n",
    "        # for batch norm\n",
    "        self.bn1 = nn.BatchNorm1d(rnn_hidden_size*self.num_directions) \n",
    "\n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim, i.e. seq_size)\n",
    "            x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "                They are used to find the final vector of each sequence: (batch,)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded = self.emb(x_in)      # (batch, seq_size)->(batch, seq_size, feat_size) ; E.g., (64,19)->(64,19,100)\n",
    "        \n",
    "        y_out, _ = self.rnn(x_embedded)  # (batch, seq_size, feat_size) -> (batch, seq_size, hidden_size*num_directions)\n",
    "                                         # (64,19,100) -> (64,19,64*num_directions)\n",
    "\n",
    "        #y_out = y_out_last.squeeze(dim=0)  # convert (1, batch, hidden_size*num_directions) to (batch, hidden_size*num_directions)\n",
    "        \n",
    "        if x_lengths is not None:\n",
    "            y_out = column_summation(y_out, x_lengths, mode=\"mean\") # mode is either max or mean\n",
    "            #y_out = column_gather(y_out, x_lengths)  # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "                                                     # (64, 64*num_direction)\n",
    "                                                     # but, the last hidden vector of last character, not including padding\n",
    "                                                     # e.g., get the last hidden vetor from (batch_no, 9) instead of (batch_no, 18).\n",
    "            # uncomment code below for task 2, and comment out the line above.\n",
    "            # y_out gets the max or mean hidden vector of each input\n",
    "            #y_out = column_summation(y_out, x_lengths, mode=\"max\") \n",
    "        else:\n",
    "            y_out = y_out[:, -1, :]      # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "                                         # (64, 64*num_direction)\n",
    "            \n",
    "        # with batch norm and dropout\n",
    "        y_out = F.relu(self.bn1(self.fc1(F.dropout(y_out, 0.2, training=self.training))))\n",
    "\n",
    "        \n",
    "        # with dropout\n",
    "        y_out = self.fc2(F.dropout(y_out, 0.2, training=self.training))   # y_out: (batch, num_classes) ; (64, 18)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    tweet_csv=\"data/Corona_NLP_final.csv\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch6/surname_classification\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=300,\n",
    "    rnn_hidden_size=96,\n",
    "    bidirectional=False,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "# create dataset and vectorizer\n",
    "dataset = TweetDataset.load_dataset_and_make_vectorizer(args.tweet_csv)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = TweetClassifier(embedding_size=args.char_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.tweet_vocab),\n",
    "                               num_classes=len(vectorizer.sentiment_vocab),\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.tweet_vocab.mask_index,\n",
    "                               bidirectional=args.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length # max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<MASK>': 0,\n",
       " '<UNK>': 1,\n",
       " '<BEGIN>': 2,\n",
       " '<END>': 3,\n",
       " 'britain': 4,\n",
       " 's': 5,\n",
       " 'frontline': 6,\n",
       " 'minimum': 7,\n",
       " 'wage': 8,\n",
       " 'army': 9,\n",
       " 'got': 10,\n",
       " 'a': 11,\n",
       " 'pay': 12,\n",
       " 'rise': 13,\n",
       " 'today': 14,\n",
       " 'national': 15,\n",
       " 'reality': 16,\n",
       " 'hr': 17,\n",
       " 'over': 18,\n",
       " 'remember': 19,\n",
       " 'that': 20,\n",
       " 'the': 21,\n",
       " 'next': 22,\n",
       " 'time': 23,\n",
       " 'you': 24,\n",
       " 'see': 25,\n",
       " 'them': 26,\n",
       " 'working': 27,\n",
       " 'in': 28,\n",
       " 'supermarket': 29,\n",
       " 'cleaning': 30,\n",
       " 'hospital': 31,\n",
       " 'or': 32,\n",
       " 'providing': 33,\n",
       " 'care': 34,\n",
       " 'perfect': 35,\n",
       " 'storm': 36,\n",
       " 'u': 37,\n",
       " 'facing': 38,\n",
       " 'hunger': 39,\n",
       " 'crisis': 40,\n",
       " 'demand': 41,\n",
       " 'for': 42,\n",
       " 'food': 43,\n",
       " 'bank': 44,\n",
       " 'soar': 45,\n",
       " 'public': 46,\n",
       " 'health': 47,\n",
       " 'is': 48,\n",
       " 'many': 49,\n",
       " 'faceted': 50,\n",
       " 'issue': 51,\n",
       " 'not': 52,\n",
       " 'just': 53,\n",
       " 'one': 54,\n",
       " 'coronavirus': 55,\n",
       " 'http': 56,\n",
       " 't': 57,\n",
       " 'co': 58,\n",
       " 'lbxn': 59,\n",
       " 'jfw': 60,\n",
       " 'cole': 61,\n",
       " 'woolworth': 62,\n",
       " 'lgnsw': 63,\n",
       " 'ritapanahi': 64,\n",
       " 'alanjones': 65,\n",
       " 'shouldn': 66,\n",
       " 'be': 67,\n",
       " 'halting': 68,\n",
       " 'use': 69,\n",
       " 'of': 70,\n",
       " 'reusable': 71,\n",
       " 'bag': 72,\n",
       " 'while': 73,\n",
       " 'we': 74,\n",
       " 'are': 75,\n",
       " 'trying': 76,\n",
       " 'to': 77,\n",
       " 'contain': 78,\n",
       " 'covid': 79,\n",
       " 'high': 80,\n",
       " 'traffic': 81,\n",
       " 'at': 82,\n",
       " 'moment': 83,\n",
       " 'coupled': 84,\n",
       " 'with': 85,\n",
       " 'potential': 86,\n",
       " 'infection': 87,\n",
       " 'spread': 88,\n",
       " 'from': 89,\n",
       " 'infected': 90,\n",
       " 'surface': 91,\n",
       " 'oil': 92,\n",
       " 'price': 93,\n",
       " 'trump': 94,\n",
       " 'expects': 95,\n",
       " 'russia': 96,\n",
       " 'and': 97,\n",
       " 'saudi': 98,\n",
       " 'arabia': 99,\n",
       " 'settle': 100,\n",
       " 'dispute': 101,\n",
       " 'soon': 102,\n",
       " 'check': 103,\n",
       " 'it': 104,\n",
       " 'out': 105,\n",
       " 'here': 106,\n",
       " 'dzoncy': 107,\n",
       " 'z': 108,\n",
       " 'outbreak': 109,\n",
       " 'investing': 110,\n",
       " 'stock': 111,\n",
       " 'lse': 112,\n",
       " 'equity': 113,\n",
       " 'finance': 114,\n",
       " 'uknews': 115,\n",
       " 'market': 116,\n",
       " 'update': 117,\n",
       " 'haxxv': 118,\n",
       " 'ljq': 119,\n",
       " 'where': 120,\n",
       " 'your': 121,\n",
       " 'gouging': 122,\n",
       " 'police': 123,\n",
       " 'excedrin': 124,\n",
       " 'seriously': 125,\n",
       " 'twitter': 126,\n",
       " 'please': 127,\n",
       " 'shame': 128,\n",
       " 'these': 129,\n",
       " 'sorry': 130,\n",
       " 'as': 131,\n",
       " 'scrub': 132,\n",
       " 'denmark': 133,\n",
       " 'us': 134,\n",
       " 'trick': 135,\n",
       " 'avoid': 136,\n",
       " 'selfish': 137,\n",
       " 'buying': 138,\n",
       " 'bottle': 139,\n",
       " 'kr': 140,\n",
       " 'rm': 141,\n",
       " 'if': 142,\n",
       " 'malaysia': 143,\n",
       " 'should': 144,\n",
       " 'apply': 145,\n",
       " 'this': 146,\n",
       " 'instead': 147,\n",
       " 'selling': 148,\n",
       " 'kelik': 149,\n",
       " 'mekoh': 150,\n",
       " 'balik': 151,\n",
       " 'hari': 152,\n",
       " 'handsanitizer': 153,\n",
       " 'gj': 154,\n",
       " 'ukubpqp': 155,\n",
       " 'pmoindia': 156,\n",
       " 'narendramodi': 157,\n",
       " 'dear': 158,\n",
       " 'sir': 159,\n",
       " 'my': 160,\n",
       " 'humble': 161,\n",
       " 'request': 162,\n",
       " 'ban': 163,\n",
       " 'tiktok': 164,\n",
       " 'till': 165,\n",
       " 'lockdown': 166,\n",
       " 'people': 167,\n",
       " 'spreading': 168,\n",
       " 'fall': 169,\n",
       " 'information': 170,\n",
       " 'hanta': 171,\n",
       " 'virus': 172,\n",
       " 'shortage': 173,\n",
       " 'grocery': 174,\n",
       " 'stocking': 175,\n",
       " 'fake': 176,\n",
       " 'corona': 177,\n",
       " 'vaccine': 178,\n",
       " 'etc': 179,\n",
       " 'coronaviruslockdown': 180,\n",
       " 'coronaviruspandemic': 181,\n",
       " 'everyday': 182,\n",
       " 'walmart': 183,\n",
       " 'ceo': 184,\n",
       " 'dougmcmillon': 185,\n",
       " 'tell': 186,\n",
       " 'lie': 187,\n",
       " 'about': 188,\n",
       " 'how': 189,\n",
       " 'company': 190,\n",
       " 'protecting': 191,\n",
       " 'associate': 192,\n",
       " 'have': 193,\n",
       " 'no': 194,\n",
       " 'hand': 195,\n",
       " 'sanitizer': 196,\n",
       " 'ppe': 197,\n",
       " 'hundred': 198,\n",
       " 'customer': 199,\n",
       " 'they': 200,\n",
       " 'counted': 201,\n",
       " 'limited': 202,\n",
       " 'option': 203,\n",
       " 'but': 204,\n",
       " 'come': 205,\n",
       " 'work': 206,\n",
       " 'get': 207,\n",
       " 'paid': 208,\n",
       " 'essentialworker': 209,\n",
       " 'mini': 210,\n",
       " 'uv': 211,\n",
       " 'wand': 212,\n",
       " 'handheld': 213,\n",
       " 'ultra': 214,\n",
       " 'violet': 215,\n",
       " 'light': 216,\n",
       " 'kill': 217,\n",
       " 'bacteria': 218,\n",
       " 'germ': 219,\n",
       " 'sterilizer': 220,\n",
       " 'vylmtuziqr': 221,\n",
       " 'peutnitlvc': 222,\n",
       " 'exclusive': 223,\n",
       " 'break': 224,\n",
       " 'consumer': 225,\n",
       " 'credit': 226,\n",
       " 'score': 227,\n",
       " 'industry': 228,\n",
       " 'persuaded': 229,\n",
       " 'congress': 230,\n",
       " 'protect': 231,\n",
       " 'who': 232,\n",
       " 'miss': 233,\n",
       " 'payment': 234,\n",
       " 'due': 235,\n",
       " 'group': 236,\n",
       " 'disagrees': 237,\n",
       " 'amp': 238,\n",
       " 'push': 239,\n",
       " 'back': 240,\n",
       " 'cdnpoli': 241,\n",
       " 'vanpoli': 242,\n",
       " 'bcpoli': 243,\n",
       " 'fintrac': 244,\n",
       " 'canada': 245,\n",
       " 'bankofcanada': 246,\n",
       " 'mvbyegwvwo': 247,\n",
       " 'i': 248,\n",
       " 'live': 249,\n",
       " 'house': 250,\n",
       " 'five': 251,\n",
       " 'different': 252,\n",
       " 'store': 253,\n",
       " 'worker': 254,\n",
       " 'three': 255,\n",
       " 'all': 256,\n",
       " 'contact': 257,\n",
       " 're': 258,\n",
       " 'up': 259,\n",
       " 'eating': 260,\n",
       " 'roommate': 261,\n",
       " 'dinner': 262,\n",
       " 'sharing': 263,\n",
       " 'horror': 264,\n",
       " 'story': 265,\n",
       " 'our': 266,\n",
       " 'day': 267,\n",
       " 'pm': 268,\n",
       " 'benice': 269,\n",
       " 'pibfactcheck': 270,\n",
       " 'antibiotic': 271,\n",
       " 'do': 272,\n",
       " 'against': 273,\n",
       " 'since': 274,\n",
       " 'only': 275,\n",
       " 'can': 276,\n",
       " 'effective': 277,\n",
       " 'preventing': 278,\n",
       " 'fact': 279,\n",
       " 'trusted': 280,\n",
       " 'source': 281,\n",
       " 'beware': 282,\n",
       " 'fakenews': 283,\n",
       " 'coronavirusupdate': 284,\n",
       " 'pyfqvtlsne': 285,\n",
       " 'distance': 286,\n",
       " 'learning': 287,\n",
       " 'thousandoakshs': 288,\n",
       " 'begin': 289,\n",
       " 'email': 290,\n",
       " 'teacher': 291,\n",
       " 'coming': 292,\n",
       " 'fast': 293,\n",
       " 'furious': 294,\n",
       " 'schedule': 295,\n",
       " 'class': 296,\n",
       " 'case': 297,\n",
       " 'need': 298,\n",
       " 'keep': 299,\n",
       " 'everything': 300,\n",
       " 'straight': 301,\n",
       " 'good': 302,\n",
       " 'luck': 303,\n",
       " 'lancer': 304,\n",
       " 'yc': 305,\n",
       " 'jc': 306,\n",
       " 'jw': 307,\n",
       " 'mass': 308,\n",
       " 'yesterday': 309,\n",
       " 'hypermarket': 310,\n",
       " 'station': 311,\n",
       " 'bus': 312,\n",
       " 'rnr': 313,\n",
       " 'towards': 314,\n",
       " 'beloved': 315,\n",
       " 'hometown': 316,\n",
       " 'love': 317,\n",
       " 'waiting': 318,\n",
       " 'ha': 319,\n",
       " 'voice': 320,\n",
       " 'piped': 321,\n",
       " 'telling': 322,\n",
       " 'shop': 323,\n",
       " 'doing': 324,\n",
       " 'possible': 325,\n",
       " 'shopping': 326,\n",
       " 'when': 327,\n",
       " 'safety': 328,\n",
       " 'their': 329,\n",
       " 'staff': 330,\n",
       " 'falling': 331,\n",
       " 'mile': 332,\n",
       " 'short': 333,\n",
       " 'had': 334,\n",
       " 'chain': 335,\n",
       " 'welcoming': 336,\n",
       " 'social': 337,\n",
       " 'into': 338,\n",
       " 'early': 339,\n",
       " 'access': 340,\n",
       " 'alongside': 341,\n",
       " 'nh': 342,\n",
       " 'd': 343,\n",
       " 'suggest': 344,\n",
       " 'bringing': 345,\n",
       " 'along': 346,\n",
       " 'id': 347,\n",
       " 'going': 348,\n",
       " 'find': 349,\n",
       " 'opening': 350,\n",
       " 'go': 351,\n",
       " 'ru': 352,\n",
       " 'kaargo': 353,\n",
       " 'nif': 354,\n",
       " 'sfjpgf': 355,\n",
       " 'southwest': 356,\n",
       " 'iowa': 357,\n",
       " 'renewable': 358,\n",
       " 'energy': 359,\n",
       " 'president': 360,\n",
       " 'mike': 361,\n",
       " 'jerke': 362,\n",
       " 'note': 363,\n",
       " 'effect': 364,\n",
       " 'on': 365,\n",
       " 'his': 366,\n",
       " 'ethanol': 367,\n",
       " 'plant': 368,\n",
       " 've': 369,\n",
       " 'put': 370,\n",
       " 'plan': 371,\n",
       " 'place': 372,\n",
       " 'currently': 373,\n",
       " 'operating': 374,\n",
       " 'reduced': 375,\n",
       " 'rate': 376,\n",
       " 'tsggqdljpj': 377,\n",
       " 'happyeaster': 378,\n",
       " 'chocolate': 379,\n",
       " 'flower': 380,\n",
       " 'homeessentials': 381,\n",
       " 'appreciated': 382,\n",
       " 'clorox': 383,\n",
       " 'bleach': 384,\n",
       " 'toiletpaper': 385,\n",
       " 'stayhome': 386,\n",
       " 'socialdistancing': 387,\n",
       " 'evelynperezlarin': 388,\n",
       " 'realtor': 389,\n",
       " 'miami': 390,\n",
       " 'fortuneinternationalrealty': 391,\n",
       " 'canvasmiami': 392,\n",
       " 'weareinthistogether': 393,\n",
       " 'n': 394,\n",
       " 'hxvssuai': 395,\n",
       " 'household': 396,\n",
       " 'product': 397,\n",
       " 'expert': 398,\n",
       " 'helping': 399,\n",
       " 'relieve': 400,\n",
       " 'quarantine': 401,\n",
       " 'boredom': 402,\n",
       " 'savant': 403,\n",
       " 'aignos': 404,\n",
       " 'printed': 405,\n",
       " 'book': 406,\n",
       " 'cd': 407,\n",
       " 'dvd': 408,\n",
       " 'ordered': 409,\n",
       " 'publisher': 410,\n",
       " 'off': 411,\n",
       " 'suggested': 412,\n",
       " 'retail': 413,\n",
       " 'through': 414,\n",
       " 'may': 415,\n",
       " 'using': 416,\n",
       " 'discount': 417,\n",
       " 'code': 418,\n",
       " 'checkout': 419,\n",
       " 'jv': 420,\n",
       " 'jbipx': 421,\n",
       " 'booksale': 422,\n",
       " 'gun': 423,\n",
       " 'metro': 424,\n",
       " 'atlanta': 425,\n",
       " 'line': 426,\n",
       " 'six': 427,\n",
       " 'eight': 428,\n",
       " 'deep': 429,\n",
       " 'been': 430,\n",
       " 'stripped': 431,\n",
       " 'bare': 432,\n",
       " 'by': 433,\n",
       " 'fear': 434,\n",
       " 'ammunition': 435,\n",
       " 'started': 436,\n",
       " 'flying': 437,\n",
       " 'shelf': 438,\n",
       " 'ca': 439,\n",
       " 'mz': 440,\n",
       " 'abl': 441,\n",
       " 'govjqe': 442,\n",
       " 'found': 443,\n",
       " 'last': 444,\n",
       " 'plus': 445,\n",
       " 'living': 446,\n",
       " 'muslim': 447,\n",
       " 'area': 448,\n",
       " 'thought': 449,\n",
       " 'were': 450,\n",
       " 'empty': 451,\n",
       " 'morning': 452,\n",
       " 'wine': 453,\n",
       " 'largely': 454,\n",
       " 'untouched': 455,\n",
       " 'yee': 456,\n",
       " 'coronacrisis': 457,\n",
       " 'panicbuying': 458,\n",
       " 'week': 459,\n",
       " 'crazy': 460,\n",
       " 'm': 461,\n",
       " 'incredibly': 462,\n",
       " 'lucky': 463,\n",
       " 'best': 464,\n",
       " 'friend': 465,\n",
       " 'cook': 466,\n",
       " 'clean': 467,\n",
       " 'doe': 468,\n",
       " 'run': 469,\n",
       " 'so': 470,\n",
       " 'don': 471,\n",
       " 'thank': 472,\n",
       " 'loved': 473,\n",
       " 'there': 474,\n",
       " 'supporting': 475,\n",
       " 'front': 476,\n",
       " 'right': 477,\n",
       " 'now': 478,\n",
       " 'idtwitter': 479,\n",
       " 'flotus': 480,\n",
       " 'potus': 481,\n",
       " 'umbrella': 482,\n",
       " 'an': 483,\n",
       " 'affordable': 484,\n",
       " 'solution': 485,\n",
       " 'implement': 486,\n",
       " 'foot': 487,\n",
       " 'pharmacy': 488,\n",
       " 'instantaneously': 489,\n",
       " 'ask': 490,\n",
       " 'american': 491,\n",
       " 'open': 492,\n",
       " 'sedskigao': 493,\n",
       " 'give': 494,\n",
       " 'thanks': 495,\n",
       " 'keeping': 496,\n",
       " 'essential': 497,\n",
       " 'stocked': 498,\n",
       " 'across': 499,\n",
       " 'uk': 500,\n",
       " 'thankyouthursday': 501,\n",
       " 'irurjsfakw': 502,\n",
       " 'will': 503,\n",
       " 'closed': 504,\n",
       " 'end': 505,\n",
       " 'march': 506,\n",
       " 'safe': 507,\n",
       " 'during': 508,\n",
       " 'continue': 509,\n",
       " 'fulfill': 510,\n",
       " 'ship': 511,\n",
       " 'order': 512,\n",
       " 'placed': 513,\n",
       " 'online': 514,\n",
       " 'pickup': 515,\n",
       " 'available': 516,\n",
       " 'until': 517,\n",
       " 'return': 518,\n",
       " 'regular': 519,\n",
       " 'hour': 520,\n",
       " 'h': 521,\n",
       " 'dqbipbub': 522,\n",
       " 'cryptogodfatha': 523,\n",
       " 'imo': 524,\n",
       " 'close': 525,\n",
       " 'bottom': 526,\n",
       " 'contrary': 527,\n",
       " 'popular': 528,\n",
       " 'bitcoin': 529,\n",
       " 'gold': 530,\n",
       " 'investor': 531,\n",
       " 'worldwide': 532,\n",
       " 'risk': 533,\n",
       " 'crypto': 534,\n",
       " 'result': 535,\n",
       " 'wait': 536,\n",
       " 'opportunity': 537,\n",
       " 'pandemic': 538,\n",
       " 'cryptoc': 539,\n",
       " 'caused': 540,\n",
       " 'serious': 541,\n",
       " 'disruption': 542,\n",
       " 'business': 543,\n",
       " 'argenio': 544,\n",
       " 'antao': 545,\n",
       " 'share': 546,\n",
       " 'top': 547,\n",
       " 'concern': 548,\n",
       " 'realestate': 549,\n",
       " 'stakeholder': 550,\n",
       " 'navigate': 551,\n",
       " 'impact': 552,\n",
       " 'conversation': 553,\n",
       " 'ybhsmvflut': 554,\n",
       " 'read': 555,\n",
       " 'more': 556,\n",
       " 'typ': 557,\n",
       " 'kqm': 558,\n",
       " 'om': 559,\n",
       " 'tincss': 560,\n",
       " 'nin': 561,\n",
       " 'never': 562,\n",
       " 'ever': 563,\n",
       " 'falsely': 564,\n",
       " 'accused': 565,\n",
       " 'being': 566,\n",
       " 'twice': 567,\n",
       " 'min': 568,\n",
       " 'buy': 569,\n",
       " 'than': 570,\n",
       " 'pack': 571,\n",
       " 'loo': 572,\n",
       " 'roll': 573,\n",
       " 'oh': 574,\n",
       " 'what': 575,\n",
       " 'panicshopping': 576,\n",
       " 'employee': 577,\n",
       " 'amazon': 578,\n",
       " 'warehouse': 579,\n",
       " 'balzac': 580,\n",
       " 'tested': 581,\n",
       " 'positive': 582,\n",
       " 'spoke': 583,\n",
       " 'infectious': 584,\n",
       " 'disease': 585,\n",
       " 'mean': 586,\n",
       " 'detail': 587,\n",
       " 'globalcalgary': 588,\n",
       " 'dfwd': 589,\n",
       " 'gsta': 590,\n",
       " 'statebank': 591,\n",
       " 'pak': 592,\n",
       " 'decent': 593,\n",
       " 'decision': 594,\n",
       " 'wake': 595,\n",
       " 'deceleration': 596,\n",
       " 'surprising': 597,\n",
       " 'weak': 598,\n",
       " 'stance': 599,\n",
       " 'statement': 600,\n",
       " 'fiscal': 601,\n",
       " 'slippage': 602,\n",
       " 'aishagpasha': 603,\n",
       " 'fawadchaudhry': 604,\n",
       " 'circulardebt': 605,\n",
       " 'soelosses': 606,\n",
       " 'privatization': 607,\n",
       " 'coronavirusi': 608,\n",
       " 'government': 609,\n",
       " 'help': 610,\n",
       " 'making': 611,\n",
       " 'small': 612,\n",
       " 'manufacturer': 613,\n",
       " 'produce': 614,\n",
       " 'per': 615,\n",
       " 'guideline': 616,\n",
       " 'increase': 617,\n",
       " 'production': 618,\n",
       " 'sanitizers': 619,\n",
       " 'flourish': 620,\n",
       " 'every': 621,\n",
       " 'pocket': 622,\n",
       " 'coronaviru': 623,\n",
       " 'sent': 624,\n",
       " 'brother': 625,\n",
       " 'map': 626,\n",
       " 'grade': 627,\n",
       " 'him': 628,\n",
       " 'percentage': 629,\n",
       " 'upon': 630,\n",
       " 'based': 631,\n",
       " 'main': 632,\n",
       " 'objective': 633,\n",
       " 'completed': 634,\n",
       " 'well': 635,\n",
       " 'side': 636,\n",
       " 'quest': 637,\n",
       " 'quarantinelife': 638,\n",
       " 'videogamesinreallife': 639,\n",
       " 'iv': 640,\n",
       " 'bl': 641,\n",
       " 'j': 642,\n",
       " 'take': 643,\n",
       " 'existing': 644,\n",
       " 'meet': 645,\n",
       " 'especially': 646,\n",
       " 'true': 647,\n",
       " 'emerging': 648,\n",
       " 'cpg': 649,\n",
       " 'brand': 650,\n",
       " 'like': 651,\n",
       " 'operation': 652,\n",
       " 'disrupted': 653,\n",
       " 'uncertainty': 654,\n",
       " 'fcj': 655,\n",
       " 'cikknv': 656,\n",
       " 'bb': 657,\n",
       " 'ylsqu': 658,\n",
       " 'scene': 659,\n",
       " 'would': 660,\n",
       " 'fighting': 661,\n",
       " 'flour': 662,\n",
       " 'hugging': 663,\n",
       " 'each': 664,\n",
       " 'other': 665,\n",
       " 'because': 666,\n",
       " 'managed': 667,\n",
       " 'toilet': 668,\n",
       " 'loud': 669,\n",
       " 'cheer': 670,\n",
       " 'paracetamol': 671,\n",
       " 'brought': 672,\n",
       " 'morrison': 673,\n",
       " 'blyth': 674,\n",
       " 'massive': 675,\n",
       " 'queses': 676,\n",
       " 'big': 677,\n",
       " 'gap': 678,\n",
       " 'panic': 679,\n",
       " 'borisjohnson': 680,\n",
       " 'consider': 681,\n",
       " 'activating': 682,\n",
       " 'some': 683,\n",
       " 'sort': 684,\n",
       " 'regulated': 685,\n",
       " 'distribution': 686,\n",
       " 'enforce': 687,\n",
       " 'considerate': 688,\n",
       " 'worse': 689,\n",
       " 'zib': 690,\n",
       " 'dadc': 691,\n",
       " 'pamybot': 692,\n",
       " 'forex': 693,\n",
       " 'fxdailyfx': 694,\n",
       " 'silver': 695,\n",
       " 'fascinating': 696,\n",
       " 'counterintuitively': 697,\n",
       " 'economic': 698,\n",
       " 'hit': 699,\n",
       " 'become': 700,\n",
       " 'horribly': 701,\n",
       " 'apparent': 702,\n",
       " 'rebound': 703,\n",
       " 'afoot': 704,\n",
       " 'davidcottlefx': 705,\n",
       " 'xgeif': 706,\n",
       " 'vrq': 707,\n",
       " 'reason': 708,\n",
       " 'pile': 709,\n",
       " 'scared': 710,\n",
       " 'scarce': 711,\n",
       " 'future': 712,\n",
       " 'emptying': 713,\n",
       " 'faster': 714,\n",
       " 'supply': 715,\n",
       " 'restock': 716,\n",
       " 'cause': 717,\n",
       " 'creating': 718,\n",
       " 'very': 719,\n",
       " 'thing': 720,\n",
       " 'prevent': 721,\n",
       " 'water': 722,\n",
       " 'sign': 723,\n",
       " 'member': 724,\n",
       " 'opec': 725,\n",
       " 'cartel': 726,\n",
       " 'ally': 727,\n",
       " 'agreed': 728,\n",
       " 'withhold': 729,\n",
       " 'almost': 730,\n",
       " 'barrel': 731,\n",
       " 'month': 732,\n",
       " 'after': 733,\n",
       " 'wiped': 734,\n",
       " 'fossil': 735,\n",
       " 'fuel': 736,\n",
       " 'triggered': 737,\n",
       " 'collapse': 738,\n",
       " 'global': 739,\n",
       " 'via': 740,\n",
       " 'those': 741,\n",
       " 'saving': 742,\n",
       " 'life': 743,\n",
       " 'shift': 744,\n",
       " 'without': 745,\n",
       " 'joined': 746,\n",
       " 'mp': 747,\n",
       " 'calling': 748,\n",
       " 'secretary': 749,\n",
       " 'retailer': 750,\n",
       " 'action': 751,\n",
       " 'ensure': 752,\n",
       " 'enough': 753,\n",
       " 'provision': 754,\n",
       " 'minnesotan': 755,\n",
       " 'emergency': 756,\n",
       " 'little': 757,\n",
       " 'way': 758,\n",
       " 'protection': 759,\n",
       " 'sunrisers': 760,\n",
       " 'xabro': 761,\n",
       " 'dm': 762,\n",
       " 'okay': 763,\n",
       " 'problem': 764,\n",
       " 'minuet': 765,\n",
       " 'govandybeshear': 766,\n",
       " 'make': 767,\n",
       " 'announcement': 768,\n",
       " 'stop': 769,\n",
       " 'nasty': 770,\n",
       " 'getting': 771,\n",
       " 'cussed': 772,\n",
       " 'threatened': 773,\n",
       " 'limiting': 774,\n",
       " 'item': 775,\n",
       " 'state': 776,\n",
       " 'healthathome': 777,\n",
       " 'positivit': 778,\n",
       " 'mum': 779,\n",
       " 'most': 780,\n",
       " 'overwhelmed': 781,\n",
       " 'rudeness': 782,\n",
       " 'dad': 783,\n",
       " 'came': 784,\n",
       " 'home': 785,\n",
       " 'hunt': 786,\n",
       " 'favourite': 787,\n",
       " 'bouquet': 788,\n",
       " 'guy': 789,\n",
       " 'cue': 790,\n",
       " 'aw': 791,\n",
       " 'bchapman': 792,\n",
       " 'around': 793,\n",
       " 'world': 794,\n",
       " 'nut': 795,\n",
       " 'isn': 796,\n",
       " 'deadly': 797,\n",
       " 'think': 798,\n",
       " 'hoard': 799,\n",
       " 'mask': 800,\n",
       " 'figure': 801,\n",
       " 'senior': 802,\n",
       " 'immunosuppressed': 803,\n",
       " 'stay': 804,\n",
       " 'healthy': 805,\n",
       " 'gdg': 806,\n",
       " 'lj': 807,\n",
       " 'x': 808,\n",
       " 'airenangel': 809,\n",
       " 'madam': 810,\n",
       " 'baka': 811,\n",
       " 'di': 812,\n",
       " 'nyo': 813,\n",
       " 'naranasan': 814,\n",
       " 'ang': 815,\n",
       " 'isang': 816,\n",
       " 'kahig': 817,\n",
       " 'tuka': 818,\n",
       " 'thats': 819,\n",
       " 'why': 820,\n",
       " 'someone': 821,\n",
       " 'still': 822,\n",
       " 'realizing': 823,\n",
       " 'least': 824,\n",
       " 'hoping': 825,\n",
       " 'leave': 826,\n",
       " 'country': 827,\n",
       " 'govt': 828,\n",
       " 'capped': 829,\n",
       " 'firm': 830,\n",
       " 'overcharging': 831,\n",
       " 'amid': 832,\n",
       " 'threat': 833,\n",
       " 'consumeraffairs': 834,\n",
       " 'minister': 835,\n",
       " 'ram': 836,\n",
       " 'vila': 837,\n",
       " 'paswan': 838,\n",
       " 'tweeted': 839,\n",
       " 'ml': 840,\n",
       " 'sold': 841,\n",
       " 'r': 842,\n",
       " 'ireland': 843,\n",
       " 'irish': 844,\n",
       " 'shopper': 845,\n",
       " 'set': 846,\n",
       " 'sale': 847,\n",
       " 'record': 848,\n",
       " 'surge': 849,\n",
       " 'believe': 850,\n",
       " 'hasn': 851,\n",
       " 'said': 852,\n",
       " 'yet': 853,\n",
       " 'paper': 854,\n",
       " 'factory': 855,\n",
       " 'quaratinelife': 856,\n",
       " 'charmin': 857,\n",
       " 'quiltednorthern': 858,\n",
       " 'new': 859,\n",
       " 'delivery': 860,\n",
       " 'waitlist': 861,\n",
       " 'dtt': 862,\n",
       " 'qhtsgg': 863,\n",
       " 'braced': 864,\n",
       " 'weekend': 865,\n",
       " 'chaos': 866,\n",
       " 'warns': 867,\n",
       " 'former': 868,\n",
       " 'waitrose': 869,\n",
       " 'bos': 870,\n",
       " 'ogojs': 871,\n",
       " 'ony': 872,\n",
       " 'daily': 873,\n",
       " 'express': 874,\n",
       " 'ki': 875,\n",
       " 'cxucrbl': 876,\n",
       " 'made': 877,\n",
       " 'me': 878,\n",
       " 'smile': 879,\n",
       " 'st': 880,\n",
       " 'bernard': 881,\n",
       " 'such': 882,\n",
       " 'resourceful': 883,\n",
       " 'breed': 884,\n",
       " 'juddlegum': 885,\n",
       " 'kylekulinski': 886,\n",
       " 'worked': 887,\n",
       " 'pmd': 888,\n",
       " 'bet': 889,\n",
       " 'even': 890,\n",
       " 'despite': 891,\n",
       " 'breathe': 892,\n",
       " 'cover': 893,\n",
       " 'nose': 894,\n",
       " 'mouth': 895,\n",
       " 'community': 896,\n",
       " 'interested': 897,\n",
       " 'finding': 898,\n",
       " 'happen': 899,\n",
       " 'property': 900,\n",
       " 'restriction': 901,\n",
       " 'nerida': 902,\n",
       " 'conisbee': 903,\n",
       " 'chief': 904,\n",
       " 'economist': 905,\n",
       " 'rea': 906,\n",
       " 'present': 907,\n",
       " 'latest': 908,\n",
       " 'smartline': 909,\n",
       " 'iunqsgiem': 910,\n",
       " 'qn': 911,\n",
       " 'imanrdh': 912,\n",
       " 'aoeuidan': 913,\n",
       " 'laurenl': 914,\n",
       " 'getmebadges': 915,\n",
       " 'realdonaldtrump': 916,\n",
       " 'medium': 917,\n",
       " 'won': 918,\n",
       " 'patient': 919,\n",
       " 'charged': 920,\n",
       " 'free': 921,\n",
       " 'kept': 922,\n",
       " 'sufficient': 923,\n",
       " 'needn': 924,\n",
       " 'swarm': 925,\n",
       " 'superma': 926,\n",
       " 'attention': 927,\n",
       " 'everyone': 928,\n",
       " 'smart': 929,\n",
       " 'wash': 930,\n",
       " 'frequently': 931,\n",
       " 'practice': 932,\n",
       " 'distancing': 933,\n",
       " 'doesn': 934,\n",
       " 'hard': 935,\n",
       " 'manlyquarantinesurvivaltips': 936,\n",
       " 'stayathome': 937,\n",
       " 'scammer': 938,\n",
       " 'illegal': 939,\n",
       " 'robocalls': 940,\n",
       " 'pitch': 941,\n",
       " 'scam': 942,\n",
       " 'treatment': 943,\n",
       " 'scheme': 944,\n",
       " 'annoying': 945,\n",
       " 'unwanted': 946,\n",
       " 'call': 947,\n",
       " 'press': 948,\n",
       " 'any': 949,\n",
       " 'number': 950,\n",
       " 'hang': 951,\n",
       " 'learn': 952,\n",
       " 'could': 953,\n",
       " 'plunge': 954,\n",
       " 'much': 955,\n",
       " 'spring': 956,\n",
       " 'v': 957,\n",
       " 'year': 958,\n",
       " 'predicted': 959,\n",
       " 'website': 960,\n",
       " 'buyer': 961,\n",
       " 'dropped': 962,\n",
       " 'analysis': 963,\n",
       " 'trading': 964,\n",
       " 'clearing': 965,\n",
       " 'settlement': 966,\n",
       " 'pse': 967,\n",
       " 'sccp': 968,\n",
       " 'tomorrow': 969,\n",
       " 'further': 970,\n",
       " 'notice': 971,\n",
       " 'enhanced': 972,\n",
       " 'implemented': 973,\n",
       " 'luzon': 974,\n",
       " 'zuitmcir': 975,\n",
       " 'shannonrwatts': 976,\n",
       " 'glad': 977,\n",
       " 'he': 978,\n",
       " 'excited': 979,\n",
       " 'bought': 980,\n",
       " 'pantry': 981,\n",
       " 'frozen': 982,\n",
       " 'starting': 983,\n",
       " 'ago': 984,\n",
       " 'dr': 985,\n",
       " 'fauci': 986,\n",
       " 'calmly': 987,\n",
       " 'ready': 988,\n",
       " 'worry': 989,\n",
       " 'afford': 990,\n",
       " 'law': 991,\n",
       " 'review': 992,\n",
       " 'delay': 993,\n",
       " 'ccpa': 994,\n",
       " 'enforcement': 995,\n",
       " 'uvwgjlxqtk': 996,\n",
       " 'cybersecurity': 997,\n",
       " 'data': 998,\n",
       " 'jjra': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.tweet_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negative': 0, 'Positive': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.sentiment_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b02bb98d3634fdf9f09c9eb77eb86ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311febd990a241ef85dc3fb318a5b587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d782835f504414a2a2061a7103351b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'],         # (batch, seq_size) ; e.g., (64,19)\n",
    "                                x_lengths=batch_dict['x_length'])  # (batch,) ; e.g, (64,)\n",
    "                                                                   # y_pred: (batch, num_classes) ; e.g., (64,18)\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 1\n",
    "        val_bar.n = 1\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_sentiment_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'],\n",
    "                         x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_sentiment_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4721630233891156;\n",
      "Test Accuracy: 76.75382653061224\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "sentiment_classes = []\n",
    "for i in range(len(dataset._vectorizer.sentiment_vocab)):\n",
    "    sentiment_classes.append(dataset._vectorizer.sentiment_vocab.lookup_index(i))\n",
    "print(sentiment_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       Negative  Positive\n",
      "Predicted                    \n",
      "Negative       1439       554\n",
      "Positive        175       968\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_sentiment_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=sentiment_classes, columns=sentiment_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80      1614\n",
      "           1       0.85      0.64      0.73      1522\n",
      "\n",
      "    accuracy                           0.77      3136\n",
      "   macro avg       0.78      0.76      0.76      3136\n",
      "weighted avg       0.78      0.77      0.76      3136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_sentiment_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
